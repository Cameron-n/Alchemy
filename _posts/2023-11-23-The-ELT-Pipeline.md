---
title: "The ELT Pipeline"
layout: post
---

# Introduction

The E stand for Extraction,
The L stands for Load,
The T stands for transform.

So it looks like we only need, at most, three programs to get our data pipeline going, right?
... If only it was that simple.

Welcome to my project on setting up a simple data pipeline using entirely open-source software. Like any project, what starts off simple soon becomes complex, even if the intial task seems straightforward. We are going to cover the instillation of all the needed programs, and then configure them to take some data from a public source on the web and send it to a data analysis tool. This will only focus on locally hosted software. We leave the cloud for another day.

# Overview

This is a list of all the programs we will need to install.

| Program          | Purpose          |
|------------------|------------------|
| Anaconda         | Package manager for Python|
| Python           | General Purpose Language  |
| Spyder           | Python Editor             |
| Git              | Version control           |
| WSL              | Allows Linux on Windows   |
| Docker           | Infrastructure            |
| SQL (MySQL)      | Database                  |
| Airbyte          | The EL of ELT             |
| dbt              | The T of ELT              |
| SuperSet         | BI tool                   |

We will install them in that order. Feel free to skip ahead if you already have some programs installed, but check back if something goes wrong.

# Anaconda, Python, and Spyder (and cmd)

# Git

# WSL 2, Linux, and Docker Desktop

# MySQL

# Airbyte

# dbt

# SuperSet

# Connecting Google Sheets to MySQL

# To the analysis and beyond!





